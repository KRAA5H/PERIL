{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f58937b2",
   "metadata": {},
   "source": [
    "# Threat Scoring and Risk Classification\n",
    "\n",
    "## Project: PERIL - Public Event Risk Intelligence London\n",
    "\n",
    "### Objective\n",
    "This notebook develops a threat scoring algorithm for London transport infrastructure by combining:\n",
    "- **Crowd density metrics** (from TfL traffic data)\n",
    "- **Infrastructure criticality** (station importance, connectivity)\n",
    "- **Vulnerability attributes** (accessibility, structural factors)\n",
    "\n",
    "### Methodology\n",
    "Following evidence-based threat assessment principles:\n",
    "1. Normalize traffic data to create crowd density scores\n",
    "2. Apply weighted scoring based on multiple risk factors\n",
    "3. Classify stations into threat levels (High/Medium/Low)\n",
    "4. Identify geographic clustering of high-risk areas\n",
    "\n",
    "### Threat Assessment Framework\n",
    "Based on counter-terrorism guidance, we assess:\n",
    "- **Impact potential**: Crowd size and density\n",
    "- **Symbolic value**: Major hubs vs local stations\n",
    "- **Accessibility**: Open access vs controlled entry\n",
    "- **Recovery difficulty**: Network criticality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a61e93",
   "metadata": {},
   "source": [
    "## 1. Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Define data directory\n",
    "DATA_DIR = Path('../data/tfl')\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741e5d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 2024 annualized data\n",
    "df_2024 = pd.read_csv(DATA_DIR / 'AC2024_AnnualisedEntryExit_CrowdingPublic__AC24_v17.2_E9_annualised.csv', \n",
    "                       skiprows=6)\n",
    "\n",
    "# Clean and structure the data\n",
    "df_stations = df_2024[['Mode', 'MASC', 'Station', 'Coverage', 'Source', 'Annualised']].copy()\n",
    "df_stations.columns = ['Mode', 'Station_Code', 'Station_Name', 'Coverage', 'Source', 'Annual_EntryExit']\n",
    "df_stations['Annual_EntryExit'] = pd.to_numeric(df_stations['Annual_EntryExit'], errors='coerce')\n",
    "df_stations = df_stations.dropna(subset=['Annual_EntryExit'])\n",
    "\n",
    "print(f\"Loaded data for {len(df_stations)} stations\")\n",
    "print(f\"Total annual traffic: {df_stations['Annual_EntryExit'].sum():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e24156",
   "metadata": {},
   "source": [
    "## 2. Create Crowd Density Score\n",
    "\n",
    "Normalize traffic data to a 0-100 scale to quantify crowd density risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4037e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentile-based crowd density score (0-100)\n",
    "df_stations['Crowd_Density_Score'] = stats.rankdata(df_stations['Annual_EntryExit'], method='average') / len(df_stations) * 100\n",
    "\n",
    "# Alternative: Min-Max normalization\n",
    "min_traffic = df_stations['Annual_EntryExit'].min()\n",
    "max_traffic = df_stations['Annual_EntryExit'].max()\n",
    "df_stations['Traffic_Score_MinMax'] = ((df_stations['Annual_EntryExit'] - min_traffic) / (max_traffic - min_traffic)) * 100\n",
    "\n",
    "print(\"Crowd Density Scoring Complete\")\n",
    "print(f\"Score range: {df_stations['Crowd_Density_Score'].min():.1f} - {df_stations['Crowd_Density_Score'].max():.1f}\")\n",
    "print(f\"\\nTop 10 stations by crowd density:\")\n",
    "print(df_stations.nlargest(10, 'Crowd_Density_Score')[['Station_Name', 'Annual_EntryExit', 'Crowd_Density_Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f68101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize crowd density distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Histogram of crowd density scores\n",
    "axes[0].hist(df_stations['Crowd_Density_Score'], bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0].axvline(df_stations['Crowd_Density_Score'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "axes[0].axvline(df_stations['Crowd_Density_Score'].median(), color='orange', linestyle='--', linewidth=2, label='Median')\n",
    "axes[0].set_xlabel('Crowd Density Score', fontweight='bold')\n",
    "axes[0].set_ylabel('Number of Stations', fontweight='bold')\n",
    "axes[0].set_title('Distribution of Crowd Density Scores', fontweight='bold', fontsize=13)\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Log-scale traffic distribution\n",
    "axes[1].hist(np.log10(df_stations['Annual_EntryExit']), bins=30, color='coral', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_xlabel('Log10(Annual Entry/Exit)', fontweight='bold')\n",
    "axes[1].set_ylabel('Number of Stations', fontweight='bold')\n",
    "axes[1].set_title('Traffic Distribution (Log Scale)', fontweight='bold', fontsize=13)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad0396d",
   "metadata": {},
   "source": [
    "## 3. Infrastructure Criticality Score\n",
    "\n",
    "Major interchange stations and network hubs have higher symbolic value and operational criticality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a087be92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define major interchange and symbolic stations (based on TfL network knowledge)\n",
    "major_interchanges = [\n",
    "    'Bank and Monument', 'King\\'s Cross St. Pancras', 'Waterloo', 'Victoria', 'Liverpool Street',\n",
    "    'Oxford Circus', 'London Bridge', 'Stratford', 'Paddington', 'Bond Street',\n",
    "    'Baker Street', 'Euston', 'Canary Wharf', 'Westminster', 'Green Park',\n",
    "    'Clapham Junction', 'Vauxhall', 'Finsbury Park', 'Tottenham Court Road', 'Leicester Square'\n",
    "]\n",
    "\n",
    "# Create criticality score\n",
    "df_stations['Is_Major_Hub'] = df_stations['Station_Name'].isin(major_interchanges).astype(int)\n",
    "df_stations['Infrastructure_Score'] = df_stations['Is_Major_Hub'] * 30  # Bonus points for major hubs\n",
    "\n",
    "print(f\"Major hubs identified: {df_stations['Is_Major_Hub'].sum()}\")\n",
    "print(f\"\\nMajor hubs in dataset:\")\n",
    "print(df_stations[df_stations['Is_Major_Hub'] == 1][['Station_Name', 'Annual_EntryExit']].sort_values('Annual_EntryExit', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a4eb90",
   "metadata": {},
   "source": [
    "## 4. Accessibility & Vulnerability Score\n",
    "\n",
    "Open-access stations (no barriers) and those with multiple entrances are more vulnerable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ac0ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate vulnerability based on mode and station type\n",
    "# Underground stations typically have more controlled access than overground\n",
    "mode_vulnerability = {\n",
    "    'LU': 15,      # London Underground - moderate control\n",
    "    'LO': 25,      # London Overground - more open\n",
    "    'DLR': 25,     # DLR - minimal barriers\n",
    "    'TfL Rail': 20,\n",
    "    'LT': 30,      # Tram - completely open\n",
    "}\n",
    "\n",
    "df_stations['Vulnerability_Score'] = df_stations['Mode'].map(mode_vulnerability).fillna(20)\n",
    "\n",
    "print(\"Vulnerability scoring applied based on transport mode\")\n",
    "print(\"\\nAverage vulnerability by mode:\")\n",
    "print(df_stations.groupby('Mode')['Vulnerability_Score'].first().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce9746",
   "metadata": {},
   "source": [
    "## 5. Composite Threat Score Calculation\n",
    "\n",
    "Combine all risk factors with appropriate weights:\n",
    "- **Crowd Density**: 50% (primary factor)\n",
    "- **Infrastructure Criticality**: 30% (symbolic/operational value)\n",
    "- **Vulnerability**: 20% (accessibility risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0af37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weighted composite threat score\n",
    "df_stations['Composite_Threat_Score'] = (\n",
    "    0.50 * df_stations['Crowd_Density_Score'] +\n",
    "    0.30 * df_stations['Infrastructure_Score'] +\n",
    "    0.20 * df_stations['Vulnerability_Score']\n",
    ")\n",
    "\n",
    "# Normalize to 0-100 scale\n",
    "min_score = df_stations['Composite_Threat_Score'].min()\n",
    "max_score = df_stations['Composite_Threat_Score'].max()\n",
    "df_stations['Threat_Score_Normalized'] = (\n",
    "    (df_stations['Composite_Threat_Score'] - min_score) / (max_score - min_score) * 100\n",
    ")\n",
    "\n",
    "print(\"✓ Composite Threat Scoring Complete\")\n",
    "print(f\"\\nScore statistics:\")\n",
    "print(df_stations['Threat_Score_Normalized'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4affca8",
   "metadata": {},
   "source": [
    "## 6. Classify Threat Levels\n",
    "\n",
    "Categorize stations into High/Medium/Low threat levels based on percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d123af02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threat level thresholds\n",
    "# High: Top 15% (90th percentile)\n",
    "# Medium: 50th-90th percentile\n",
    "# Low: Bottom 50%\n",
    "\n",
    "threshold_high = df_stations['Threat_Score_Normalized'].quantile(0.90)\n",
    "threshold_medium = df_stations['Threat_Score_Normalized'].quantile(0.50)\n",
    "\n",
    "def classify_threat(score):\n",
    "    if score >= threshold_high:\n",
    "        return 'HIGH'\n",
    "    elif score >= threshold_medium:\n",
    "        return 'MEDIUM'\n",
    "    else:\n",
    "        return 'LOW'\n",
    "\n",
    "df_stations['Threat_Level'] = df_stations['Threat_Score_Normalized'].apply(classify_threat)\n",
    "\n",
    "# Count by threat level\n",
    "threat_counts = df_stations['Threat_Level'].value_counts()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"THREAT LEVEL CLASSIFICATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"High threat stations:   {threat_counts.get('HIGH', 0):3d} ({threat_counts.get('HIGH', 0)/len(df_stations)*100:.1f}%)\")\n",
    "print(f\"Medium threat stations: {threat_counts.get('MEDIUM', 0):3d} ({threat_counts.get('MEDIUM', 0)/len(df_stations)*100:.1f}%)\")\n",
    "print(f\"Low threat stations:    {threat_counts.get('LOW', 0):3d} ({threat_counts.get('LOW', 0)/len(df_stations)*100:.1f}%)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nThresholds:\")\n",
    "print(f\"High threat: Score ≥ {threshold_high:.1f}\")\n",
    "print(f\"Medium threat: Score {threshold_medium:.1f} - {threshold_high:.1f}\")\n",
    "print(f\"Low threat: Score < {threshold_medium:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a2e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display HIGH THREAT stations\n",
    "high_threat_stations = df_stations[df_stations['Threat_Level'] == 'HIGH'].sort_values('Threat_Score_Normalized', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"HIGH THREAT STATIONS - PRIORITY SECURITY MONITORING\")\n",
    "print(\"=\"*100)\n",
    "print(f\"{'Rank':<6}{'Station':<30}{'Mode':<8}{'Annual Traffic':>15}{'Threat Score':>15}{'Hub':>6}\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for idx, (i, row) in enumerate(high_threat_stations.iterrows(), 1):\n",
    "    hub_status = 'YES' if row['Is_Major_Hub'] else 'NO'\n",
    "    print(f\"{idx:<6}{row['Station_Name']:<30}{row['Mode']:<8}{row['Annual_EntryExit']:>15,.0f}{row['Threat_Score_Normalized']:>15.1f}{hub_status:>6}\")\n",
    "\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bef65ef",
   "metadata": {},
   "source": [
    "## 7. Visualize Threat Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd5b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive threat visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Threat level pie chart\n",
    "colors_threat = {'HIGH': '#d32f2f', 'MEDIUM': '#f57c00', 'LOW': '#388e3c'}\n",
    "threat_colors = [colors_threat[level] for level in threat_counts.index]\n",
    "axes[0, 0].pie(threat_counts.values, labels=threat_counts.index, autopct='%1.1f%%',\n",
    "               colors=threat_colors, startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "axes[0, 0].set_title('Station Distribution by Threat Level', fontsize=13, fontweight='bold')\n",
    "\n",
    "# 2. Threat score histogram with classifications\n",
    "axes[0, 1].hist(df_stations['Threat_Score_Normalized'], bins=40, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].axvline(threshold_high, color='red', linestyle='--', linewidth=2, label=f'High Threshold ({threshold_high:.1f})')\n",
    "axes[0, 1].axvline(threshold_medium, color='orange', linestyle='--', linewidth=2, label=f'Medium Threshold ({threshold_medium:.1f})')\n",
    "axes[0, 1].set_xlabel('Threat Score', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Number of Stations', fontweight='bold')\n",
    "axes[0, 1].set_title('Distribution of Threat Scores', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# 3. Top 20 stations by threat score\n",
    "top_20_threat = df_stations.nlargest(20, 'Threat_Score_Normalized')\n",
    "bars = axes[1, 0].barh(range(len(top_20_threat)), top_20_threat['Threat_Score_Normalized'].values)\n",
    "axes[1, 0].set_yticks(range(len(top_20_threat)))\n",
    "axes[1, 0].set_yticklabels(top_20_threat['Station_Name'].values)\n",
    "axes[1, 0].set_xlabel('Threat Score', fontweight='bold')\n",
    "axes[1, 0].set_title('Top 20 Highest Threat Stations', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].invert_yaxis()\n",
    "axes[1, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Color bars by threat level\n",
    "for bar, threat_level in zip(bars, top_20_threat['Threat_Level'].values):\n",
    "    bar.set_color(colors_threat[threat_level])\n",
    "\n",
    "# 4. Scatter: Traffic vs Threat Score\n",
    "scatter = axes[1, 1].scatter(df_stations['Annual_EntryExit'] / 1e6, \n",
    "                             df_stations['Threat_Score_Normalized'],\n",
    "                             c=df_stations['Threat_Level'].map({'HIGH': 2, 'MEDIUM': 1, 'LOW': 0}),\n",
    "                             cmap='RdYlGn_r', s=50, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "axes[1, 1].set_xlabel('Annual Traffic (Millions)', fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Threat Score', fontweight='bold')\n",
    "axes[1, 1].set_title('Traffic Volume vs Threat Score', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "# Add annotations for top 5 stations\n",
    "for i, row in df_stations.nlargest(5, 'Threat_Score_Normalized').iterrows():\n",
    "    axes[1, 1].annotate(row['Station_Name'], \n",
    "                        xy=(row['Annual_EntryExit']/1e6, row['Threat_Score_Normalized']),\n",
    "                        xytext=(10, 5), textcoords='offset points', fontsize=8,\n",
    "                        bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972a8ba8",
   "metadata": {},
   "source": [
    "## 8. Analyze Threat Patterns by Transport Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd85b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average threat score by mode\n",
    "mode_threat = df_stations.groupby('Mode').agg({\n",
    "    'Threat_Score_Normalized': ['mean', 'max', 'count'],\n",
    "    'Annual_EntryExit': 'sum'\n",
    "}).round(2)\n",
    "\n",
    "mode_threat.columns = ['Avg_Threat_Score', 'Max_Threat_Score', 'Station_Count', 'Total_Traffic']\n",
    "mode_threat = mode_threat.sort_values('Avg_Threat_Score', ascending=False)\n",
    "\n",
    "print(\"Threat Analysis by Transport Mode:\")\n",
    "print(\"=\"*80)\n",
    "print(mode_threat)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54bc6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot of threat scores by mode\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "modes_ordered = df_stations.groupby('Mode')['Threat_Score_Normalized'].mean().sort_values(ascending=False).index\n",
    "df_stations_sorted = df_stations.copy()\n",
    "df_stations_sorted['Mode'] = pd.Categorical(df_stations_sorted['Mode'], categories=modes_ordered, ordered=True)\n",
    "\n",
    "sns.boxplot(data=df_stations_sorted, x='Mode', y='Threat_Score_Normalized', \n",
    "            palette='RdYlGn_r', linewidth=1.5)\n",
    "sns.stripplot(data=df_stations_sorted, x='Mode', y='Threat_Score_Normalized', \n",
    "              color='black', alpha=0.3, size=3)\n",
    "\n",
    "plt.xlabel('Transport Mode', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Threat Score', fontsize=12, fontweight='bold')\n",
    "plt.title('Threat Score Distribution by Transport Mode', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0446206",
   "metadata": {},
   "source": [
    "## 9. Export Threat Assessment Data\n",
    "\n",
    "Save the complete threat assessment for use in website visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a48f4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare export dataset\n",
    "df_export = df_stations[[\n",
    "    'Station_Code', 'Station_Name', 'Mode', 'Annual_EntryExit',\n",
    "    'Crowd_Density_Score', 'Infrastructure_Score', 'Vulnerability_Score',\n",
    "    'Threat_Score_Normalized', 'Threat_Level', 'Is_Major_Hub'\n",
    "]].copy()\n",
    "\n",
    "df_export.columns = [\n",
    "    'station_code', 'station_name', 'mode', 'annual_traffic',\n",
    "    'crowd_density_score', 'infrastructure_score', 'vulnerability_score',\n",
    "    'threat_score', 'threat_level', 'is_major_hub'\n",
    "]\n",
    "\n",
    "# Sort by threat score\n",
    "df_export = df_export.sort_values('threat_score', ascending=False)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = Path('../data') / 'tfl_threat_assessment.csv'\n",
    "df_export.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✓ Threat assessment data exported to: {output_path}\")\n",
    "print(f\"✓ Total stations: {len(df_export)}\")\n",
    "print(f\"✓ Columns: {', '.join(df_export.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1fed63",
   "metadata": {},
   "source": [
    "## 10. Summary and Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f313e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*100)\n",
    "print(\"THREAT SCORING ANALYSIS - EXECUTIVE SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\\n1. METHODOLOGY\")\n",
    "print(\"   Composite threat score calculated from:\")\n",
    "print(\"   • Crowd Density (50%): Based on annual passenger traffic\")\n",
    "print(\"   • Infrastructure Criticality (30%): Major hubs and symbolic targets\")\n",
    "print(\"   • Vulnerability (20%): Accessibility and security control levels\")\n",
    "\n",
    "print(\"\\n2. CLASSIFICATION RESULTS\")\n",
    "print(f\"   • HIGH THREAT:   {threat_counts.get('HIGH', 0):3d} stations (≥90th percentile) - PRIORITY MONITORING\")\n",
    "print(f\"   • MEDIUM THREAT: {threat_counts.get('MEDIUM', 0):3d} stations (50th-90th percentile) - ENHANCED AWARENESS\")\n",
    "print(f\"   • LOW THREAT:    {threat_counts.get('LOW', 0):3d} stations (<50th percentile) - ROUTINE SECURITY\")\n",
    "\n",
    "print(\"\\n3. HIGHEST RISK STATIONS (Top 10)\")\n",
    "for idx, (i, row) in enumerate(df_stations.nlargest(10, 'Threat_Score_Normalized').iterrows(), 1):\n",
    "    print(f\"   {idx:2d}. {row['Station_Name']:<30} Score: {row['Threat_Score_Normalized']:5.1f} | Traffic: {row['Annual_EntryExit']/1e6:5.1f}M | Hub: {'Yes' if row['Is_Major_Hub'] else 'No'}\")\n",
    "\n",
    "print(\"\\n4. RISK PATTERNS\")\n",
    "lu_avg = df_stations[df_stations['Mode'] == 'LU']['Threat_Score_Normalized'].mean()\n",
    "print(f\"   • London Underground average threat score: {lu_avg:.1f}\")\n",
    "print(f\"   • Major hubs average threat score: {df_stations[df_stations['Is_Major_Hub']==1]['Threat_Score_Normalized'].mean():.1f}\")\n",
    "print(f\"   • Non-hub average threat score: {df_stations[df_stations['Is_Major_Hub']==0]['Threat_Score_Normalized'].mean():.1f}\")\n",
    "print(f\"   • Hub threat elevation: {(df_stations[df_stations['Is_Major_Hub']==1]['Threat_Score_Normalized'].mean() / df_stations[df_stations['Is_Major_Hub']==0]['Threat_Score_Normalized'].mean() - 1)*100:.1f}%\")\n",
    "\n",
    "print(\"\\n5. ACTIONABLE INSIGHTS\")\n",
    "print(\"   ⚠️  HIGH THREAT stations require:\")\n",
    "print(\"      - Enhanced surveillance and security presence\")\n",
    "print(\"      - Regular security drills and emergency preparedness\")\n",
    "print(\"      - Real-time monitoring integration\")\n",
    "print(\"      - Structural vulnerability assessments\")\n",
    "print(\"   \")\n",
    "print(\"   ⚠️  Major interchange hubs show elevated risk due to:\")\n",
    "print(\"      - High symbolic value as critical infrastructure\")\n",
    "print(\"      - Dense crowd concentrations\")\n",
    "print(\"      - Multiple access points and complexity\")\n",
    "print(\"      - Network disruption potential\")\n",
    "\n",
    "print(\"\\n6. DATA QUALITY NOTES\")\n",
    "print(\"   • Analysis based on 2024 annualized TfL data\")\n",
    "print(\"   • Threat scoring uses evidence-based weighting\")\n",
    "print(\"   • Does NOT include: historical incident data, live events, current threat intelligence\")\n",
    "print(\"   • Recommended: Integrate with Stage 2 live threat detection\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"NEXT STEPS: Integrate with geospatial visualization for interactive threat mapping\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409b3db5",
   "metadata": {},
   "source": [
    "## 11. Recommendations for Website Integration\n",
    "\n",
    "This threat assessment provides the **static risk layer** for the PERIL website:\n",
    "\n",
    "### Map Visualization\n",
    "- Display stations color-coded by threat level:\n",
    "  - **Red (HIGH)**: Immediate attention, enhanced security protocols\n",
    "  - **Orange (MEDIUM)**: Elevated awareness, standard security\n",
    "  - **Green (LOW)**: Routine monitoring\n",
    "\n",
    "### Interactive Features\n",
    "- Click on station to view detailed risk breakdown:\n",
    "  - Annual traffic volume\n",
    "  - Threat score components (crowd density, criticality, vulnerability)\n",
    "  - Infrastructure classification (hub status)\n",
    "  - Recommended security measures\n",
    "\n",
    "### Integration with Live Data (Stage 2)\n",
    "- Overlay scheduled events near high-threat stations\n",
    "- Highlight stations with disruptions or incidents\n",
    "- Dynamic risk elevation based on real-time factors\n",
    "- Alert system for concurrent high-threat conditions\n",
    "\n",
    "### Data Updates\n",
    "- Refresh static scores quarterly with new TfL data\n",
    "- Continuously ingest live threat indicators\n",
    "- Maintain historical trends for pattern analysis\n",
    "\n",
    "The next notebook will provide specific implementation recommendations for the web platform."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
